const express = require("express");
const cors = require("cors");
const multer = require("multer");
const fs = require("fs");
const { GoogleGenAI } = require("@google/genai");
const { createClient } = require("@supabase/supabase-js");
const { GoogleGenerativeAI } = require("@google/generative-ai");

const pdfParse = require("pdf-parse");
const e = require("express");
require("dotenv").config();

const app = express();
app.use(express.json());
app.use(cors());

const genAI = new GoogleGenerativeAI( process.env.GEMINI_API_KEY);
let model;

(async () => {
    try {
        
        model = await genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
        console.log("Model initialized:", model);
    } catch (err) {
        console.error("Error initializing Generative Model:", err.message);
    }
})();
// Supabase initialization
const supabaseUrl = "https://hqqljqflmtgbstsbpuoq.supabase.co";
const supabaseKey = process.env.SUPABASE_KEY;
const supabase = createClient(supabaseUrl, supabaseKey);

// Storage setup for multer
const storage = multer.diskStorage({
  destination: function (req, file, cb) {
    return cb(null, "./public/images");
  },
  filename: function (req, file, cb) {
    return cb(null, `${Date.now()}_${file.originalname}`);
  },
});

const upload = multer({ storage });

// Endpoint to upload PDF
app.post("/upload", upload.single("file"), (req, res) => {
  if (req.file) {
    const filePath = req.file.path;

    // Read and parse the PDF
    fs.readFile(filePath, (err, data) => {
      if (err) {
        console.error("Error reading file:", err);
        return res.status(500).send("Error reading file");
      }

      pdfParse(data)
        .then(function (pdfData) {
          const extractedText = pdfData.text;

          if (extractedText.trim() === "") {
            return res.status(400).send("No text extracted from the PDF");
          }

          main(extractedText);
          res.send(extractedText);
        })
        .catch((error) => {
          console.error("Error parsing PDF:", error);
          return res.status(500).send("Error parsing PDF");
        });
    });
  } else {
    res.status(400).send("No file uploaded");
  }
});

// Function to generate embeddings
async function main(extractedText) {
  try {
    const apiKey = process.env.GEMINI_API_KEY;
    const ai = new GoogleGenAI({ apiKey });

    const response = await ai.models.embedContent({
      model: "gemini-embedding-exp-03-07",
      contents: [extractedText],
    });

    const embedding = response.embeddings[0];
    await storeEmbedding(extractedText, embedding);
  } catch (error) {
    console.error("Error generating embeddings:", error);
  }
}

// Function to store embeddings in Supabase
async function storeEmbedding(sentence, embedding) {
  try {
    let embeddingArray = embedding.values;

    if (!Array.isArray(embeddingArray)) {
      throw new Error("Embedding 'values' is not in the expected format.");
    }

    if (embeddingArray.length > 384) {
      embeddingArray = embeddingArray.slice(0, 384);
    } else if (embeddingArray.length < 384) {
      const padding = new Array(384 - embeddingArray.length).fill(0);
      embeddingArray = embeddingArray.concat(padding);
    }

    const { data, error } = await supabase
      .from("documents")
      .insert([
        {
          sentence: sentence,
          embedding: embeddingArray,
        },
      ]);

    if (error) {
      console.error("Error storing embedding in Supabase:", error);
    }
  } catch (error) {
    console.error("Error storing embedding:", error);
  }
}

// Endpoint to handle user query
app.post("/query", async (req, res) => {
  try {
    const { query } = req.body;
    console.log("Received query:", query);
    
    if (!query) {
      return res.status(400).send("Query is required.");
    }

    // Retrieve the closest matching document embeddings from Supabase
    const embeddings = await getClosestEmbeddings(query);

    // if (!embeddings || embeddings.length === 0) {
    //   return res.status(404).send("No matching documents found.");
    // }

    // Use the embeddings in a query to the LLM (Google Gemini in this case)
    const aiResponse = await queryLLMWithEmbeddings(embeddings, query);

    // Send the response from the LLM
    res.json(aiResponse);
  } catch (error) {
    console.error("Error handling query:", error);
    res.status(500).send("Internal server error");
  }
});

// Function to retrieve closest embeddings from Supabase based on the user's query
function calculateCosineSimilarity(queryEmbedding, documents) {
  console.log("Calculating cosine similarity...",documents);
  
  return documents.map((doc) => {
    if (Array.isArray(doc)) {
      console.log("hiii");
      
      // Calculate cosine similarity between query embedding and document embedding
      const similarity = cosineSimilarity(queryEmbedding, doc);
      return { embedding: doc, similarity };
    } else {
      return null;
    }
  }).filter((doc) => doc !== null).sort((a, b) => b.similarity - a.similarity);
}

async function getClosestEmbeddings(query) {
  try {
    const { data, error } = await supabase
      .from("documents")
      .select("sentence, embedding")
      .limit(5);

    if (error) {
      console.error("Error fetching data from Supabase:", error);
      return [];
    }

    if (!data || data.length === 0) {
      console.log("No documents found in the database.");
      return [];
    }

    // Parse embeddings from strings to arrays of numbers
    const embeddings = data.map((doc) => {
      try {
        return JSON.parse(doc.embedding); // Parse the embedding string
      } catch (err) {
        console.error("Error parsing embedding:", err);
        return null;
      }
    }).filter((embedding) => Array.isArray(embedding)); // Filter out invalid embeddings

    console.log("Parsed embeddings from Supabase:", embeddings);

    // Get the embedding for the query
    const queryEmbedding = await getQueryEmbedding(query);
    console.log("Query embedding:", queryEmbedding);

    // Pass the parsed embeddings array to calculateCosineSimilarity
    const closestDocuments = calculateCosineSimilarity(queryEmbedding.values, embeddings);
    console.log("Closest documents:", closestDocuments);

    return closestDocuments;
  } catch (error) {
    console.error("Error getting closest embeddings:", error);
    return null;
  }
}

// Function to calculate cosine similarity
function cosineSimilarity(vecA, vecB) {
  const dotProduct = vecA.reduce((sum, value, index) => sum + value * vecB[index], 0);
  const magnitudeA = Math.sqrt(vecA.reduce((sum, value) => sum + value * value, 0));
  const magnitudeB = Math.sqrt(vecB.reduce((sum, value) => sum + value * value, 0));

  if (magnitudeA === 0 || magnitudeB === 0) {
    return 0; // or handle it in a way that makes sense for your application
  }

  return dotProduct / (magnitudeA * magnitudeB);
}
// Function to get the embedding for the user's query using Gemini API
async function getQueryEmbedding(query) {
  const apiKey = process.env.GEMINI_API_KEY;
  const ai = new GoogleGenAI({ apiKey });

  const response = await ai.models.embedContent({
    model: "gemini-embedding-exp-03-07",
    contents: [query],
  });

  return response.embeddings[0];
}

// Function to query the LLM (Google Gemini or any other LLM)
async function queryLLMWithEmbeddings(embeddings, query) {
  const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY });
  console.log("Querying LLM with embeddings...");

  // Check if embeddings are valid and create context
  if (!embeddings || embeddings.length === 0) {
    console.error("No valid embeddings found.");
    return { error: "No relevant context found." };
  }

  // Construct the context from the closest embeddings
  const context = embeddings
    .slice(0, 3) // Use top 3 most similar embeddings
    .map((doc) => `Embedding: ${doc.embedding}, Similarity: ${doc.similarity}`)
    .join("\n");

  // Log the context and query for debugging purposes
  console.log("Context for LLM:", context);
  console.log("Query for LLM:", query);

  if (!context) {
    return { error: "No relevant context found." };
  }

  // Construct the prompt for the LLM
  const prompt = `Given the following context:\n${context}\n\nAnswer the question: ${query}`;
  
  try {
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();
    
    console.log("Response text from LLM:", response);
    return { response };
  } catch (error) {
    console.error("Error generating content from LLM:", error);
    return { error: "Error generating response." };
  }
}

// Start server
app.listen(8000, () => {
  console.log("Server is running on port 8000");
});
